Desviación estándar
La desviación estándar es la medida de dispersión más común, que indica qué tan dispersos están los datos con respecto a la media. Mientras mayor sea la desviación estándar, mayor será la dispersión de los datos.
El símbolo σ (sigma) se utiliza frecuentemente para representar la desviación estándar de una población, mientras que s se utiliza para representar la desviación estándar de una muestra.
La desviación estándar se puede utilizar para establecer un valor de referencia para estimar la variación general de un proceso.

.

Solo para aclarar, ya que el termino de varianza se abordo muy rápidamente:
.

Varianza: es una medida de dispersión que representa la variabilidad de una serie de datos respecto a su media. Formalmente se calcula como la suma de los residuos al cuadrado divididos entre el total de observaciones. Su fórmula es la siguiente:
X → Variable sobre la que se pretenden calcular la varianza
xi → Observación número i de la variable X. i puede tomará valores entre 1 y n.
N → Número de observaciones.
x̄ → Es la media de la variable X.
La diferencia entre la desviación estándar o típica y la varianza, es que la la desviación típica es la raíz cuadrada de la varianza
.
Y no nos podemos olvidar de otra medida de dispersión muy importante, que es el coeficiente de variación:

Su cálculo se obtiene de dividir la desviación típica entre el valor absoluto de la media del conjunto y por lo general se expresa en porcentaje para su mejor comprensión.

X → Variable sobre la que se pretenden calcular la varianza
σx → Desviación típica de la variable X.
| x̄ | → Es la media de la variable X en valor absoluto con x̄ ≠ 0
El coeficiente de variación de utiliza para comparar la dispersión (variación) de conjuntos de datos de medidas diferentes o con medias aritméticas diferentes.